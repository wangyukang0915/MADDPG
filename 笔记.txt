named_parameters()和self.parameters()这两个的区别是什么？作用又分别是什么？
    这两个方法其实都是 PyTorch nn.Module 提供的参数迭代接口，但它们返回的内容不一样，主要区别在于 是否包含参数的名字。
网络的输出值是真实的action 的概率或者是真实的q-value，然而参数是用来接近这个值的，更新参数主要是为了更好的接近真实的值。
3.因为critic网络是需要用到，新的
4.但要建立参数之间的联系，必须让这个 tensor 是通过网络的前向计算生成的，这样 autograd 才能记录它的计算路径（计算图
5. np.random.get_state()
功能：获取 NumPy 随机数生成器的当前内部状态（seed、算法状态等）。

目的：保存下来可以 在之后恢复到相同的随机数生成状态，这样后续生成的随机数序列就能和当时完全一致。

对应恢复方法：np.random.set_state(saved_state)。
import random

# 设置种子
random.seed(42)
print(random.random())  # 0.6394267984578837

# 保存种子变量（只是数值，不是状态）
seed_value = 42

# 再生成两个随机数
print(random.random())  # 0.025010755222666936
print(random.random())  # 0.27502931836911926

# 重新设置种子
random.seed(seed_value)
print(random.random())  # 0.6394267984578837（回到了序列开头，不是中间）

6.喂给神经网络的参数需要归一化处理，因为这样可以：
    输入尺度一致化：神经网络在处理输入时，如果不同特征的数值差异过大（比如速度是 01，距离是 02.8），会影响梯度更新和训练稳定性。
    加快收敛：归一化到一个统一范围（通常是 01 或 -11）有助于网络更快收敛，避免某些输入维度主导权重更新。
    泛化性：如果环境大小变化（length 改变），归一化后的输入特征尺度依然稳定，网络不需要重新适配距离的绝对大小
 然而，求奖励函数的值的时候要用到的是真实的值，所以不需要归一化进行处理

 7.SARS
    critic网络给出的结果并不是奖励函数的值，而是，state value或者action value的值

8.坐标系得转换
    我们熟悉的数学上的直角坐标系是(0,0)位中心进行的坐标分布,然而,在图形绘制的时候,坐标是按照左上角为原点进行设置的,所以要想将直角坐标系的曲线转换成可以显示的图片,就必须要先进行一部转换.